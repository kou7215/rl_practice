{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarsaの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_0 = np.array([[np.nan, 1, 1, np.nan],\n",
    "                    [np.nan, 1, np.nan, 1],\n",
    "                    [np.nan, np.nan, 1, 1],\n",
    "                    [1, 1, 1, np.nan],\n",
    "                    [np.nan, np.nan, 1, 1],\n",
    "                    [1, np.nan, np.nan, np.nan],\n",
    "                    [1, np.nan, np.nan, np.nan],\n",
    "                    [1, 1, np.nan, np.nan]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       nan, 0.8867676 , 0.43656628,        nan],\n",
       "       [       nan, 0.82495847,        nan, 0.25628574],\n",
       "       [       nan,        nan, 0.77550142, 0.2536127 ],\n",
       "       [0.25000636, 0.01399757, 0.88135403,        nan],\n",
       "       [       nan,        nan, 0.93927032, 0.54044564],\n",
       "       [0.19976126,        nan,        nan,        nan],\n",
       "       [0.2408545 ,        nan,        nan,        nan],\n",
       "       [0.24342454, 0.50557655,        nan,        nan]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a, b] = theta_0.shape\n",
    "Q = np.random.rand(a, b) * theta_0\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方策パラメータtheta_0をランダム方策piに変換する関数の定義\n",
    "\n",
    "単純に割合を計算するだけ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.5       , 0.5       , 0.        ],\n",
       "       [0.        , 0.5       , 0.        , 0.5       ],\n",
       "       [0.        , 0.        , 0.5       , 0.5       ],\n",
       "       [0.33333333, 0.33333333, 0.33333333, 0.        ],\n",
       "       [0.        , 0.        , 0.5       , 0.5       ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.5       , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_convert_into_pi_from_theta(theta):\n",
    "    m, n = theta.shape\n",
    "    pi = np.zeros((m, n))\n",
    "    for i in range(0, m):\n",
    "        pi[i, :] = theta[i, :] / np.nansum(theta[i, :])\n",
    "    \n",
    "    pi = np.nan_to_num(pi)\n",
    "    \n",
    "    return pi\n",
    "\n",
    "pi_0 = simple_convert_into_pi_from_theta(theta_0)\n",
    "pi_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ε-greedyの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(s, Q, epsilon, pi_0):\n",
    "    direction = ['up', 'right', 'down', 'left']\n",
    "    \n",
    "    # 行動を決める\n",
    "    if np.random.rand() < epsilon:\n",
    "        # epsilon以下なら方策πから行動を決定\n",
    "        # ※方策は改善されないので実質一様分布から選択. \n",
    "        next_direction = np.random.choice(direction, p=pi_0[s, :])\n",
    "    else:\n",
    "        # epsilon以上なら各s,aでの報酬に基づき評価された行動価値関数Qから次のaを選択.\n",
    "        next_direction = direction[np.nanargmax(Q[s, :])]\n",
    "    \n",
    "    if next_direction == 'up':\n",
    "        action = 0\n",
    "    elif next_direction == 'right':\n",
    "        action = 1\n",
    "    elif next_direction == 'down':\n",
    "        action = 2\n",
    "    elif next_direction == 'left':\n",
    "        action = 3\n",
    "    return action\n",
    "\n",
    "def get_s_next(s, a, Q, epsilon, pi_0):\n",
    "    direction = ['up', 'right', 'down', 'left']\n",
    "    next_direction = direction[a]\n",
    "    \n",
    "    # 行動から次の状態を決める\n",
    "    if next_direction == 'up':\n",
    "        s_next = s - 3\n",
    "    elif next_direction == 'right':\n",
    "        s_next = s + 1\n",
    "    elif next_direction == 'down':\n",
    "        s_next = s + 3\n",
    "    elif next_direction == 'left':\n",
    "        s_next = s - 1\n",
    "    return s_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learningによる行動価値関数Qの更新\n",
    "\n",
    "Sarsa同様, TD誤差を用いて行動価値関数$Q(s, a)$を更新する.<br>\n",
    "ただし, $Q$の更新に$a_{t+1}$は直接入らない. <br>\n",
    "$Q$の評価値が正しいものだと仮定して, $\\max_{a}Q(s_{t+1}, a)$として評価する.\n",
    "\n",
    "$$\n",
    "Q(s_t, a_t) \\leftarrow Q(s_t, a_t) + η(R_{t+1} + γ\\max_{a}Q(S_{t+1}, a) - Q(s_t, a_t)) \\tag{1}\n",
    "$$\n",
    "\n",
    "一方, Sarsaの更新式は,\n",
    "\n",
    "$$\n",
    "Q(s_t, a_t) \\leftarrow Q(s_t, a_t) + η(R_{t+1} + γQ(S_{t+1}, a_{t+1}) - Q(s_t, a_t)) \\tag{2}\n",
    "$$\n",
    "\n",
    "ベルマン方程式$(1)$は$Q(s, a)$が正しい値であるときに成り立つ式であるので、その誤差を最小化させるようなイメージ.\n",
    "\n",
    "$Q$の更新にする際の$a_{t+1}$がε-greedy方策に基づいていないので, Q-learningは方策オフ型アルゴリズムとなる. <br>\n",
    "一方Sarsaは, 次の行動$a_{next}$における$Q$の値を決める際に、ε-greedy方策に基づくので方策オン型アルゴリズムとなる.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_learning(s, a, r, s_next, a_next, Q, eta, gamma):\n",
    "    if s_next == 8:\n",
    "        # ゴールした場合は次の状態がないので、Q[s_next, a_next] = 0\n",
    "        Q[s, a] = Q[s, a] + eta*(r - Q[s, a])\n",
    "    else:\n",
    "        # 以下、Qの更新にはs_nextと過去の経験/greedy方策で決定したa_nextを用いるので方策オン型.\n",
    "        # Q-learningは更新式にa_nextが入らない. 過去の評価値をとにかく信頼する.\n",
    "        Q[s, a] = Q[s, a] + eta*(r + gamma*np.nanmax(Q[s_next, :]) - Q[s, a])\n",
    "        # 以下がSarsa\n",
    "        #Q[s, a] = Q[s, a] + eta*(r + gamma*Q[s_next, a_next] - Q[s, a])\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learningで迷路を解く\n",
    "\n",
    "方策勾配法と異なり、価値反復法では1エピソードごとではなく、1stepごとに更新する.\n",
    "\n",
    "ここでは方策改善はしていない点に注意。あくまで、$s$, $a$を入力とする行動価値関数$Q$のみで次の状態・行動の学習・実行をしている.\n",
    "\n",
    "Sarsaでは行動価値関数$Q$の更新に、ε-greedyに基づいて選択された$a_t$, $a_{t+1}$両方が考慮されていたが, Q-learningでは$a_t$のみ考慮する.\n",
    "\n",
    "Q-learningでは$a_t$はε-greedy, $a_{t+1}$もε-greedyで選択されるが, $Q$の更新に$a_{t+1}$は使わず, $\\max_{a}Q(s_{t+1}, a)$とする.<br>\n",
    "あくまで$a_t \\leftarrow a_{t+1}$としてアップデートするためだけにε-greedyするイミッジ. 更新式には直接入らない.<br>\n",
    "Sarsaでは$Q$更新時にε-greedyに基づいて選択された$a_{t+1}$が考慮されているため、迷路で通れない場所のゆらぎを加味して評価されるが, <br>\n",
    "Q-learningでは常に評価が正しくできていると仮定して次の評価値へ更新するため, 通れないところのギリギリを攻めたルート選択をするようになる. ただしその分収束は早い."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi):\n",
    "    s = 0\n",
    "    a = a_next = get_action(s, Q, epsilon, pi)\n",
    "    s_a_history = [[0, np.nan]]\n",
    "    \n",
    "    # 1episode終わったら状態・行動の履歴を返す.\n",
    "    while(1):\n",
    "        a = a_next\n",
    "        s_a_history[-1][1] = a\n",
    "        \n",
    "        s_next = get_s_next(s, a, Q, epsilon, pi)\n",
    "        \n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        \n",
    "        if s_next == 8:\n",
    "            r = 1\n",
    "            a_next = np.nan\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_action(s_next, Q, epsilon, pi)\n",
    "            \n",
    "        # 1 stepごとに(各s, aごとに)Qは更新される.\n",
    "        #Q = Sarsa(s, a, r, s_next, a_next, Q, eta, gamma)\n",
    "        Q = Q_learning(s, a, r, s_next, a_next, Q, eta, gamma)\n",
    "        \n",
    "        if s_next == 8:\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "    \n",
    "    return [s_a_history, Q]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実際にQ-learningで迷路問題を解いてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode :  1\n",
      "1.3896741644155246\n",
      "step in the end of episode :  174\n",
      "episode :  2\n",
      "0.7047929495151015\n",
      "step in the end of episode :  86\n",
      "episode :  3\n",
      "1.4522017950948751\n",
      "step in the end of episode :  760\n",
      "episode :  4\n",
      "0.10753095307298322\n",
      "step in the end of episode :  6\n",
      "episode :  5\n",
      "0.096057162460288\n",
      "step in the end of episode :  4\n",
      "episode :  6\n",
      "0.08585770464773002\n",
      "step in the end of episode :  4\n",
      "episode :  7\n",
      "0.07687118289744105\n",
      "step in the end of episode :  4\n",
      "episode :  8\n",
      "0.06896729108278915\n",
      "step in the end of episode :  4\n",
      "episode :  9\n",
      "0.06202626147906304\n",
      "step in the end of episode :  4\n",
      "episode :  10\n",
      "0.05626488959655468\n",
      "step in the end of episode :  4\n",
      "episode :  11\n",
      "0.05434642058627215\n",
      "step in the end of episode :  4\n",
      "episode :  12\n",
      "0.05240547312544758\n",
      "step in the end of episode :  4\n",
      "episode :  13\n",
      "0.050464043908412304\n",
      "step in the end of episode :  4\n",
      "episode :  14\n",
      "0.04853872704587936\n",
      "step in the end of episode :  4\n",
      "episode :  15\n",
      "0.046641837057433466\n",
      "step in the end of episode :  4\n",
      "episode :  16\n",
      "0.04478232108311114\n",
      "step in the end of episode :  4\n",
      "episode :  17\n",
      "0.04296649665754837\n",
      "step in the end of episode :  4\n",
      "episode :  18\n",
      "0.041198645547928514\n",
      "step in the end of episode :  4\n",
      "episode :  19\n",
      "0.03948148920182748\n",
      "step in the end of episode :  4\n",
      "episode :  20\n",
      "0.03781656715442833\n",
      "step in the end of episode :  4\n",
      "episode :  21\n",
      "0.03620453619580233\n",
      "step in the end of episode :  4\n",
      "episode :  22\n",
      "0.03464540510289976\n",
      "step in the end of episode :  4\n",
      "episode :  23\n",
      "0.033138717215834\n",
      "step in the end of episode :  4\n",
      "episode :  24\n",
      "0.03168369101384855\n",
      "step in the end of episode :  4\n",
      "episode :  25\n",
      "0.030279327062891326\n",
      "step in the end of episode :  4\n",
      "episode :  26\n",
      "0.02892448821246446\n",
      "step in the end of episode :  4\n",
      "episode :  27\n",
      "0.02761795867029343\n",
      "step in the end of episode :  4\n",
      "episode :  28\n",
      "0.02635848654168471\n",
      "step in the end of episode :  4\n",
      "episode :  29\n",
      "0.02514481355402176\n",
      "step in the end of episode :  4\n",
      "episode :  30\n",
      "0.02397569496826879\n",
      "step in the end of episode :  4\n",
      "episode :  31\n",
      "0.0228499120851946\n",
      "step in the end of episode :  4\n",
      "episode :  32\n",
      "0.021766279264442634\n",
      "step in the end of episode :  4\n",
      "episode :  33\n",
      "0.020723646972625742\n",
      "step in the end of episode :  4\n",
      "episode :  34\n",
      "0.019720902048007694\n",
      "step in the end of episode :  4\n",
      "episode :  35\n",
      "0.018756966101885153\n",
      "step in the end of episode :  4\n",
      "episode :  36\n",
      "0.017830792760245018\n",
      "step in the end of episode :  4\n",
      "episode :  37\n",
      "0.01694136427497117\n",
      "step in the end of episode :  4\n",
      "episode :  38\n",
      "0.01608768789450432\n",
      "step in the end of episode :  4\n",
      "episode :  39\n",
      "0.015268792273283593\n",
      "step in the end of episode :  4\n",
      "episode :  40\n",
      "0.014483724112348662\n",
      "step in the end of episode :  4\n",
      "episode :  41\n",
      "0.01373154515586339\n",
      "step in the end of episode :  4\n",
      "episode :  42\n",
      "0.013011329616404388\n",
      "step in the end of episode :  4\n",
      "episode :  43\n",
      "0.012322162062666453\n",
      "step in the end of episode :  4\n",
      "episode :  44\n",
      "0.01166313577426048\n",
      "step in the end of episode :  4\n",
      "episode :  45\n",
      "0.011033351547451109\n",
      "step in the end of episode :  4\n",
      "episode :  46\n",
      "0.010431916921331275\n",
      "step in the end of episode :  4\n",
      "episode :  47\n",
      "0.009857945784607858\n",
      "step in the end of episode :  4\n",
      "episode :  48\n",
      "0.009310558317793483\n",
      "step in the end of episode :  4\n",
      "episode :  49\n",
      "0.008788881223181777\n",
      "step in the end of episode :  4\n",
      "episode :  50\n",
      "0.008292048194808999\n",
      "step in the end of episode :  4\n",
      "episode :  51\n",
      "0.007819200582053654\n",
      "step in the end of episode :  4\n",
      "episode :  52\n",
      "0.0073694882031153375\n",
      "step in the end of episode :  4\n",
      "episode :  53\n",
      "0.006942070267967448\n",
      "step in the end of episode :  4\n",
      "episode :  54\n",
      "0.006536116374196932\n",
      "step in the end of episode :  4\n",
      "episode :  55\n",
      "0.006150807543186199\n",
      "step in the end of episode :  4\n",
      "episode :  56\n",
      "0.005785337268201962\n",
      "step in the end of episode :  4\n",
      "episode :  57\n",
      "0.005438912549986963\n",
      "step in the end of episode :  4\n",
      "episode :  58\n",
      "0.00511075489931212\n",
      "step in the end of episode :  4\n",
      "episode :  59\n",
      "0.004800101289579528\n",
      "step in the end of episode :  4\n",
      "episode :  60\n",
      "0.004506205045923695\n",
      "step in the end of episode :  4\n",
      "episode :  61\n",
      "0.004228336660316745\n",
      "step in the end of episode :  4\n",
      "episode :  62\n",
      "0.003965784524926352\n",
      "step in the end of episode :  4\n",
      "episode :  63\n",
      "0.003717855578415641\n",
      "step in the end of episode :  4\n",
      "episode :  64\n",
      "0.0034838758620076016\n",
      "step in the end of episode :  4\n",
      "episode :  65\n",
      "0.0032631909839786477\n",
      "step in the end of episode :  4\n",
      "episode :  66\n",
      "0.0030551664928220035\n",
      "step in the end of episode :  4\n",
      "episode :  67\n",
      "0.0028591881606386815\n",
      "step in the end of episode :  4\n",
      "episode :  68\n",
      "0.0026746621794028203\n",
      "step in the end of episode :  4\n",
      "episode :  69\n",
      "0.0025010152736267832\n",
      "step in the end of episode :  4\n",
      "episode :  70\n",
      "0.0023376947336407605\n",
      "step in the end of episode :  4\n",
      "episode :  71\n",
      "0.0021841683742237494\n",
      "step in the end of episode :  4\n",
      "episode :  72\n",
      "0.002039924423701267\n",
      "step in the end of episode :  4\n",
      "episode :  73\n",
      "0.001904471348866843\n",
      "step in the end of episode :  4\n",
      "episode :  74\n",
      "0.0017773376212273373\n",
      "step in the end of episode :  4\n",
      "episode :  75\n",
      "0.0016580714301100974\n",
      "step in the end of episode :  4\n",
      "episode :  76\n",
      "0.0015462403481372178\n",
      "step in the end of episode :  4\n",
      "episode :  77\n",
      "0.0014414309544658055\n",
      "step in the end of episode :  4\n",
      "episode :  78\n",
      "0.001343248421044163\n",
      "step in the end of episode :  4\n",
      "episode :  79\n",
      "0.0012513160669278545\n",
      "step in the end of episode :  4\n",
      "episode :  80\n",
      "0.0011652748854750206\n",
      "step in the end of episode :  4\n",
      "episode :  81\n",
      "0.001084783048980853\n",
      "step in the end of episode :  4\n",
      "episode :  82\n",
      "0.0010095153950363533\n",
      "step in the end of episode :  4\n",
      "episode :  83\n",
      "0.0009391628986187284\n",
      "step in the end of episode :  4\n",
      "episode :  84\n",
      "0.0008734321336177908\n",
      "step in the end of episode :  4\n",
      "episode :  85\n",
      "0.0008120447272271791\n",
      "step in the end of episode :  4\n",
      "episode :  86\n",
      "0.0007547368103241192\n",
      "step in the end of episode :  4\n",
      "episode :  87\n",
      "0.000701258466688448\n",
      "step in the end of episode :  4\n",
      "episode :  88\n",
      "0.0006513731836310654\n",
      "step in the end of episode :  4\n",
      "episode :  89\n",
      "0.0006048573063373031\n",
      "step in the end of episode :  4\n",
      "episode :  90\n",
      "0.0005614994979774579\n",
      "step in the end of episode :  4\n",
      "episode :  91\n",
      "0.0005211002073928217\n",
      "step in the end of episode :  4\n",
      "episode :  92\n",
      "0.00048347114594360363\n",
      "step in the end of episode :  4\n",
      "episode :  93\n",
      "0.00044843477488187844\n",
      "step in the end of episode :  4\n",
      "episode :  94\n",
      "0.0004158238044233986\n",
      "step in the end of episode :  4\n",
      "episode :  95\n",
      "0.00038548070549937474\n",
      "step in the end of episode :  4\n",
      "episode :  96\n",
      "0.00035725723500190654\n",
      "step in the end of episode :  4\n",
      "episode :  97\n",
      "0.0003310139751787622\n",
      "step in the end of episode :  4\n",
      "episode :  98\n",
      "0.00030661988768843074\n",
      "step in the end of episode :  4\n",
      "episode :  99\n",
      "0.0002839518826960319\n",
      "step in the end of episode :  4\n",
      "episode :  100\n",
      "0.000262894403277647\n",
      "step in the end of episode :  4\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 0.5\n",
    "v = np.nanmax(Q, axis=1) # 状態ごとに価値の最大値を求める.\n",
    "is_continue = True\n",
    "episode = 1\n",
    "v_losses = []\n",
    "\n",
    "while is_continue:\n",
    "    print('episode : ', episode)\n",
    "    \n",
    "    # epsilonの値を少しずつ小さくする\n",
    "    # -> だんだん経験を重視するようになる.\n",
    "    epsilon /= 2\n",
    "    \n",
    "    # Sarsaで迷路を解き、移動した履歴と更新したQを求める\n",
    "    [s_a_history, Q] = goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi_0)\n",
    "    \n",
    "    # 状態価値の変化\n",
    "    new_v = np.nanmax(Q, axis=1)\n",
    "    v_loss = np.sum(np.abs(new_v - v))\n",
    "    v_losses.append(v_loss)\n",
    "    print(v_loss)\n",
    "    v = new_v\n",
    "    \n",
    "    print('step in the end of episode : ', len(s_a_history) - 1)\n",
    "    \n",
    "    episode += 1\n",
    "    if episode > 100:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfXklEQVR4nO3de7CkdX3n8fenn+7TZ65cZo4XZoDBZNSQVQwZCKy6ihodiBuSiqvgLbpalFuS1dUyYiSarKlaXTdbaAmyU4QQ1wjZCNFZF0XNxsVahTC4ylVwAJFxQA6MMMzlXLr7u388T5/znJ5z6bk80zPn93lVnep+Lt39e+bSn/P7fX/P8ygiMDOzdNUG3QAzMxssB4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGYLkPRTSa8ZdDvMquIgMDNLnIPAzCxxDgKzPklqSrpM0vbi5zJJzWLbaklfk/SUpB2SviupVmz7sKSfS3pG0n2SXj3YIzGbqT7oBpgdRT4KnAW8BAjgq8ClwJ8CHwS2ASPFvmcBIekFwMXAGRGxXdI6IDu8zTabn3sEZv17C/AfI+LxiBgF/hx4W7FtEngucHJETEbEdyO/kFcbaAKnSmpExE8j4oGBtN5sDg4Cs/6dADxcWn64WAfwaWAr8E1JD0q6BCAitgLvB/4MeFzSdZJOwOwI4iAw69924OTS8knFOiLimYj4YEQ8D/jXwAe6tYCI+FJEvKx4bQCfOrzNNpufg8Csf9cCl0oakbQa+BjwRQBJr5f0q5IE7CQfEmpLeoGkVxVF5TFgb7HN7IjhIDDr318AW4A7gDuBHxTrANYD3wZ2Ad8HroiI75DXBz4JPAE8BjwL+JPD2mqzBcg3pjEzS5t7BGZmiXMQmJklzkFgZpY4B4GZWeKOuktMrF69OtatWzfoZpiZHVVuv/32JyJiZLZtR10QrFu3ji1btgy6GWZmRxVJD8+1zUNDZmaJcxCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWBmlrjkgyAi+PstjzA26UvEm1makg+CHz/2DB/68h3cfP/ooJtiZjYQyQfBnokWABPtzoBbYmY2GMkHwXgrD4B2xzfoMbM0OQiKIJhsOwjMLE2VBYGkqyU9LumuBfY7Q1Jb0huqast8xie7PQIPDZlZmqrsEVwDbJxvB0kZ8CngpgrbMa9ubaDloSEzS1RlQRARNwM7Ftjtj4DrgcerasdCxotpoy0PDZlZogZWI5C0Bvh94Mo+9r1I0hZJW0ZHD3yaZ0QQMfMLv1sjcI/AzFI1yGLxZcCHI2LBM7kiYlNEbIiIDSMjs95gZ0H/645HOeUjN/LA6K4Z66dnDblGYGZpGuQdyjYA10kCWA2cJ6kVEV+p4sMamQAYm5z5hT/hHoGZJW5gQRARp3SfS7oG+FpVIQDQbGQAjLdmdkC6y64RmFmqKgsCSdcCrwRWS9oGfBxoAETEgnWBQ224no+Cjff0CFwjMLPUVRYEEXHhfuz7jqra0dXtEYz19gh8HoGZJS6ZM4ubc/QIJtoeGjKztCUTBMML9Ag8NGRmqUomCObqEfiic2aWumSCYKpH0HMDmompi865RmBmaUomCKZ6BK3eHkEeDO4RmFmqHASePmpmiUsmCOpZjXpN+wwNuUZgZqlLJggg7xX09ghcIzCz1CUVBMONbJYegWsEZpa2pIJgth6BawRmlrqkgmDWHkH3hDIPDZlZopIKgqHZagS+VaWZJS6pIJi9R+AagZmlLakgmLdG4IvOmVmikgqC4UY2IwjanZgaEmr5MtRmlqikgqBZr00NBcH0OQTgoSEzS1daQdDTIyjfttLFYjNLVVJBMFyvzSgWl0PBNQIzS1VlQSDpakmPS7prju1vkXRH8fM9SadV1ZauZmNmsbg8NOQagZmlqsoewTXAxnm2PwS8IiJeDHwC2FRhWwAYrmc9PYL8eVaTawRmlqwqb15/s6R182z/XmnxFmBtVW3p6u0RjBVnFS8dypj00JCZJepIqRG8C/h61R8yXM9od2LqSqPdUFg2VHePwMySVVmPoF+SziEPgpfNs89FwEUAJ5100gF/VrMxfXOaRlabqhEsbWbs3Ns64Pc1MzuaDbRHIOnFwFXA+RHx5Fz7RcSmiNgQERtGRkYO+POa9fy+xd1zCbo1gmVDdReLzSxZAwsCSScBNwBvi4j7D8dnDhc9grHWzKGhpUMZbdcIzCxRlQ0NSboWeCWwWtI24ONAAyAirgQ+BqwCrpAE0IqIDVW1B/btEXSHhpY16z6hzMySVeWsoQsX2P5u4N1Vff5spnoEk7P0CBwEZpaoI2XW0GEx1SNo7VsjmHSNwMwSlVYQ9PYIJqdnDUVAx70CM0tQWkHQ0yPo3p1s2VA+QuY6gZmlKKkgGC6dRwDTPYIlQ3lAeAqpmaUoqSDo9gjGSucRNDLRrOd/DO4RmFmKEguCnh5Bq8NQVqNeE4DPJTCzJCUVBMONfc8jaDYysiz/Y/DMITNLUVJB0OytEbTaNOulHoGHhswsQUkFwfA+NYLOjCDwXcrMLEVJBUEjE9J0j2Ci1WGoXqOeuUdgZulKKggkzbhLWd4jyMhq3VlDrhGYWXqSCgKYeZey3hqBp4+aWYrSC4J6bepEsvHJDs2GawRmlrbkgmC4kTFWusTEUDZdI3CPwMxSlFwQ7NMjKNUI2q4RmFmCkguCco9gvNWm2ajR8NCQmSUsuSCY0SMoLjGRuVhsZglLLghm1AhaRbHYNQIzS1hyQdDbI2jWM+quEZhZwioLAklXS3pc0l1zbJekz0raKukOSadX1ZayZm+NoF4aGnKNwMwSVGWP4Bpg4zzbzwXWFz8XAZ+vsC1Tuj2CTieYbMeMS0x4aMjMUlRZEETEzcCOeXY5H/hC5G4BjpX03Kra09WsZ4y3OlO3qcyHhhwEZpauQdYI1gCPlJa3Fev2IekiSVskbRkdHT2oDx1u1BifbE/VCfJLTLhGYGbpGmQQaJZ1s/5KHhGbImJDRGwYGRk5qA/t9gi6N7BvNqZrBJOuEZhZggYZBNuAE0vLa4HtVX/ocKPGRLvD3uIKpOVLTPgy1GaWokEGwWbg7cXsobOApyPi0ao/tHsD+2fGWvlyY3r6qGsEZpaielVvLOla4JXAaknbgI8DDYCIuBK4ETgP2ArsAd5ZVVvKhovbVT69dxKg5w5lrhGYWXoqC4KIuHCB7QG8t6rPn0u3R7CzFASZh4bMLGFJnlkM00NDQ/UaDQ8NmVnCkguC4UbeI5geGsqmZg25R2BmKUouCLo9gp1j+9YIJl0jMLMEJRcE3R5BuUZQqwnJPQIzS1NyQdBsdHsExfTRonjcqNVcIzCzJCUXBMP1nhpBEQxZTZ4+amZJSi4IpnoEpaEhgHpN7hGYWZKSC4Juj6BbLB7qBkEm1wjMLEnJBcF0j6A4jyDrDg3VfNE5M0tSekFQmj5ar4l6Nj005MtQm1mKkguC7vTRPRPtqVCAfGjINQIzS1FyQdAdCoLp+gB0ewQOAjNLT3JBUKtpKgC65xBAd/qog8DM0pNcEMB0naBbOAao12q0XCMwswQlGQTdOkF5mMjTR80sVUkGwew9Ann6qJklKe0g6KkRuEdgZilKMgi6Q0Mzp4+6RmBmaao0CCRtlHSfpK2SLpll+zGS/qekH0m6W9JhuW9xNwA8fdTMrMIgkJQBlwPnAqcCF0o6tWe39wL3RMRp5De6/0tJQ1W1qWu2HkHmGoGZJarKHsGZwNaIeDAiJoDrgPN79glghSQBy4EdQKvCNgGz1wgaWc09AjNL0n4HgaSapJV97LoGeKS0vK1YV/Y54NeA7cCdwPsiYp+BekkXSdoiacvo6Oj+Nnkfc/UIfIkJM0tRX0Eg6UuSVkpaBtwD3CfpQwu9bJZ1vd+0rwN+CJwAvAT43GwhExGbImJDRGwYGRnpp8nzmqtG4BvTmFmK+u0RnBoRO4HfA24ETgLetsBrtgEnlpbXkv/mX/ZO4IbIbQUeAl7YZ5sOWHdIyNNHzcz6D4KGpAZ5EHw1IibZ97f7XrcB6yWdUhSALwA29+zzM+DVAJKeDbwAeLDfxh+o4ca+J5Q1Mt+z2MzSVO9zv/8G/BT4EXCzpJOBnfO9ICJaki4GbgIy4OqIuFvSe4rtVwKfAK6RdCf5UNKHI+KJAzqS/dCc5RITvmexmaWqryCIiM8Cny2teljSOX287kbyoaTyuitLz7cDr+2vqYfO8ByXmHCPwMxS1G+x+H1FsViS/krSD4BXVdy2yjQb+9YIfNE5M0tVvzWCf1sUi18LjJAXeT9ZWasqNn0eQe9lqB0EZpaefoOgOxX0POCvI+JHzD499KgwVSPoPY/ANQIzS1C/QXC7pG+SB8FNklYAR+235vBsPQLfs9jMEtXvrKF3kZ/w9WBE7JF0PPnw0FFp1hqBzyMws0T12yM4G7gvIp6S9FbgUuDp6ppVrdluTJMVNYIIh4GZpaXfIPg8sEfSacAfAw8DX6isVRWbutZQNnP6KOBegZklp98gaEX+q/L5wGci4jPAiuqaVa2XnHgsf3D6Wl609pipdfUsDwLXCcwsNf3WCJ6R9BHy6wu9vLjXQKO6ZlXrmCUN/vKNp81Y1+0ROAjMLDX99gjeBIyTn0/wGPnlpD9dWasGIKvlfxRt35zGzBLTVxAUX/5/Cxwj6fXAWEQctTWC2TSmhoaO2lmxZmYHpN9LTLwR+Gfg3wBvBG6V9IYqG3a4ZS4Wm1mi+q0RfBQ4IyIeB5A0Anwb+HJVDTvcujWCSQeBmSWm3xpBrRsChSf347VHhbprBGaWqH57BN+QdBNwbbH8JnouL320q7tGYGaJ6vd+BB+S9AfAS8kvNrcpIv6h0pYdZpmnj5pZovrtERAR1wPXV9iWgeoODbU8NGRmiZk3CCQ9w+z3JhYQEbGyklYNgC8xYWapmrfgGxErImLlLD8r+gkBSRsl3Sdpq6RL5tjnlZJ+KOluSf/nQA/kYGVZd9aQawRmlpa+h4b2V3EZisuB3wa2AbdJ2hwR95T2ORa4AtgYET+T9Kyq2rMQ9wjMLFVVTgE9E9gaEQ9GxARwHflF68reDNwQET8D6Jmieli5RmBmqaoyCNYAj5SWtxXryp4PHCfpO5Jul/T22d5I0kWStkjaMjo6Wklju9NH3SMws9RUGQSz3dO491u2Dvwm8DvA64A/lfT8fV4UsSkiNkTEhpGRkUPfUqanj7pGYGapqaxGQN4DOLG0vBbYPss+T0TEbmC3pJuB04D7K2zXrBo+s9jMElVlj+A2YL2kUyQNARcAm3v2+Sr5/Q3qkpYCvwXcW2Gb5uQTyswsVZX1CCKiJeli4CYgA66OiLslvafYfmVE3CvpG8AdQAe4KiLuqqpN8/ElJswsVVUODRERN9JzTaKIuLJn+dMcATe58fRRM0vVorqC6MHw9FEzS5WDoJB5aMjMEuUgKPjm9WaWKgdBwTUCM0uVg6DgGoGZpcpBUHCNwMxS5SAouEZgZqlyEBSmagQeGjKzxDgICtMXnXMQmFlaHAQFSdRrou0agZklxkFQktXkGoGZJcdBUFKvydNHzSw5DoKSrCafUGZmyXEQlDSyms8jMLPkOAhK3CMwsxQ5CErqNTHpGoGZJcZBUFLPau4RmFlyHAQldU8fNbMEVRoEkjZKuk/SVkmXzLPfGZLakt5QZXsWktVEq+1isZmlpbIgkJQBlwPnAqcCF0o6dY79PkV+k/uBqmc19wjMLDlV9gjOBLZGxIMRMQFcB5w/y35/BFwPPF5hW/pS96whM0tQlUGwBniktLytWDdF0hrg94Er53sjSRdJ2iJpy+jo6CFvaFdWE5MeGjKzxFQZBJplXe+v25cBH46I9nxvFBGbImJDRGwYGRk5ZA3s5R6BmaWoXuF7bwNOLC2vBbb37LMBuE4SwGrgPEmtiPhKhe2aUz3zrCEzS0+VQXAbsF7SKcDPgQuAN5d3iIhTus8lXQN8bVAhAPl9i/dOzts5MTNbdCoLgohoSbqYfDZQBlwdEXdLek+xfd66wCB4+qiZpajKHgERcSNwY8+6WQMgIt5RZVv60fDQkJklyGcWl/iic2aWIgdBSb1W8/RRM0uOg6CknrlHYGbpcRCU+J7FZpYiB0GJTygzsxQ5CEqyWs03pjGz5DgIShqZaPuexWaWGAdBiWsEZpYiB0FJvSZaHhoys8Q4CEp8z2IzS5GDoCS/Z7FrBGaWFgdBSVYTnYCOewVmlhAHQUkjy/84XDA2s5Q4CEqyWn5TNdcJzCwlDoKSehEErhOYWUocBCXdHoGnkJpZShwEJXXXCMwsQQ6CkrprBGaWIAdBSXdoyDenMbOUVBoEkjZKuk/SVkmXzLL9LZLuKH6+J+m0KtuzkEbmHoGZpaeyIJCUAZcD5wKnAhdKOrVnt4eAV0TEi4FPAJuqak8/spprBGaWnip7BGcCWyPiwYiYAK4Dzi/vEBHfi4hfFou3AGsrbM+CPH3UzFJUZRCsAR4pLW8r1s3lXcDXZ9sg6SJJWyRtGR0dPYRNnKnu6aNmlqAqg0CzrJv1G1bSOeRB8OHZtkfEpojYEBEbRkZGDmETZ6q7RmBmCapX+N7bgBNLy2uB7b07SXoxcBVwbkQ8WWF7FuQagZmlqMoewW3AekmnSBoCLgA2l3eQdBJwA/C2iLi/wrb0ZXpoyDUCM0tHZT2CiGhJuhi4CciAqyPibknvKbZfCXwMWAVcIQmgFREbqmrTQnxCmZmlqMqhISLiRuDGnnVXlp6/G3h3lW3YH90agYeGzCwlPrO4ZLpG4KEhM0uHg6DE00fNLEUOghJPHzWzFDkISro9gkkHgZklxEFQUi9qBG3XCMwsIQ6Cku5lqPdMtAfcEjOzw8dBUHLM0gZLhzL+bPPdXPqVO3n06b2DbpKZWeUcBCUrhxt8+wOv4I0bTuTvbnuEV/zn7/An/3AnD4zuGnTTzMwqo4ijqzC6YcOG2LJlS+Wf88iOPVzxnQe4/gfbmGx3ePULn807X7qOs5+3ilpttuvpmZkduSTdPteVGxwEC3hi1zhf+P7DfPGWh9mxe4KTVy3lTWecyBtOX8uzVg4ftnaYmR0MB8EhMDbZ5qa7H+NLt/6MWx/aQU1w9q+s4ndPO4HX/fpzOHbp0GFvk5lZvxwEh9iDo7v46g+3s/lH23noid1kNXHmuuN5zanP5lUvfBbrVi2luIiemdkRwUFQkYjgzp8/zU13P8a37vkF9/8iLyo/Z+UwZ//KKl605hhWr2iyetkQq5Y3WbV8iOOWDk1NUzUzO1wcBIfJw0/u5rs/eYLvP/gktzzwJE/unthnHwmOXzrEquVDrFqWh8Pq5U1WLRvi+NK6Vcvy5yuX1N27MLODNl8QVHoZ6tScvGoZJ69axlvPOpmIYMfuCXbsnuCJXRM8uXucJ3dN8OSucUZ3TbBj9zg7dk9w9/adPLlrnJ1jrVnfs14Txy3Lg+G4pXlYHL90iOOWDXH80gbHFeuPWzrEscXysqHM4WFmfXMQVERSMRzUZP2zF95/otVhx+7pwMif54HRXd6xe4J7t+/kl3smeGrvJHN15hqZOHbpEMcuaXDs0gbHLMlD4tglDY5Z0uCYpfnjyiUNVg4X65Y0WLmkTrOeHdo/CDM74jkIjhBD9RrPOWaY5xzT35TUdid4as8Ev9wzyVN78pB4as8kvyzWPb13evnnT+3lnu1P88s9k+ydnP/yGc16jRXDDVYO11mxJH9c3qyzYrjOiuFG6Xmd5c0Gy4frLG9mLG82WNbMWN6ss6xZp5H5XEWzo4WD4CiV1aZ7HPtjotXh6b2T7Byb5Om9+c/O7s9Yi51jk+zc2+KZsXz5mbFJHn16jGfGJnlmrNX3dZiG6jWWN+ssHcpYNlRnabN4HMpYVqzPf/LnS4YyljTy5SVDNZY06lPrljQyhodq+WMjc8iYHWKVBoGkjcBnyO9ZfFVEfLJnu4rt5wF7gHdExA+qbFPqhuo1RlY0GVmxfwHS1e4Eu8bzgNg93mbXeB4Qu8fb7B5vsWu8lT9O5I97xtvsnsi375lo8cSucXZPtNg70Wb3eHvBHsps6jWxpJHRbGQMN2oMF4/NerFcz2gWy816Lf9pTD8fqufbhuo1hrLuco1GvUazWB6q12h0n2fTy41MxWPNs79s0agsCCRlwOXAbwPbgNskbY6Ie0q7nQusL35+C/h88WhHqKymqZrCodDpBGOtNnsm2uydKB4n89AYm2yzd6LD3sk2eydajE128nWT7fx5q83YRDt/LLaNTeY9nrHJDuOtNuPF+ol2h/FWZ866yoGoiTwsshr1UkDUM1GvqfQ8D5B6bXpbPatRr4ms2C+raWo5f8z3La/PJGq1nnU1UVPv9vy2q5lETVCb2gdqmt5fYuo1te6+xfbajH3zmldNQuTrpXwG3NT+yvfprhMU+6i0H4jp13af9+5vh1+VPYIzga0R8SCApOuA84FyEJwPfCHyOay3SDpW0nMj4tEK22VHkFpNxfBQ9aOUEcFkO/JQKMJhopUHRPdxslg30X3e7j4PJlptWp2YWtdqB5PtfNtku0Or02GiFbQ65W0dWp2g1c7Xj7VialsniuedDp0OU69rR9DuWZ/avZLyoCiChOngYGp9KVRK+1Fa7r5PsXp6XWk9xXv0rtc+6/cNqKntpU1FK2ZZX36dZl1PH/tfcMaJvPvlz9unLQeryv99a4BHSsvb2Pe3/dn2WQPMCAJJFwEXAZx00kmHvKGWBkkM1TVVvziadDpFQHSCTvHY7gStTszc1qF4nodHd//u+vx5zNwW+XKnEwRBu9O9XWvxPIKIIAI6PY/B9HsFedh2pp7n+wFTn9F9TQSl9yytI39h9/Xl9d1lppb33Vbu8XXPkepuz59H6Tml/Uvru58z9Xym8vbyxpixT8yxfv/27/3w1ftZE+xXlf8bZuvj9f6Z9rMPEbEJ2AT5CWUH3zSzo0utJmqIhmf3WgWqnH6xDTixtLwW2H4A+5iZWYWqDILbgPWSTpE0BFwAbO7ZZzPwduXOAp52fcDM7PCqbGgoIlqSLgZuIp8+enVE3C3pPcX2K4EbyaeObiWfPvrOqtpjZmazq7RiFhE3kn/Zl9ddWXoewHurbIOZmc3Pp2iamSXOQWBmljgHgZlZ4hwEZmaJO+ruUCZpFHj4AF++GnjiEDbnaJHicad4zJDmcad4zLD/x31yRIzMtuGoC4KDIWnLXLdqW8xSPO4UjxnSPO4UjxkO7XF7aMjMLHEOAjOzxKUWBJsG3YABSfG4UzxmSPO4UzxmOITHnVSNwMzM9pVaj8DMzHo4CMzMEpdMEEjaKOk+SVslXTLo9lRB0omS/knSvZLulvS+Yv3xkr4l6SfF43GDbuuhJimT9P8kfa1YTuGYj5X0ZUk/Lv7Oz07kuP9D8e/7LknXShpebMct6WpJj0u6q7RuzmOU9JHiu+0+Sa/b389LIggkZcDlwLnAqcCFkk4dbKsq0QI+GBG/BpwFvLc4zkuAf4yI9cA/FsuLzfuAe0vLKRzzZ4BvRMQLgdPIj39RH7ekNcC/BzZExL8gv8T9BSy+474G2NizbtZjLP6PXwD8evGaK4rvvL4lEQTAmcDWiHgwIiaA64DzB9ymQy4iHo2IHxTPnyH/YlhDfqx/U+z2N8DvDaaF1ZC0Fvgd4KrS6sV+zCuBfwX8FUBETETEUyzy4y7UgSWS6sBS8rsaLqrjjoibgR09q+c6xvOB6yJiPCIeIr+/y5n783mpBMEa4JHS8rZi3aIlaR3wG8CtwLO7d34rHp81uJZV4jLgj4FOad1iP+bnAaPAXxdDYldJWsYiP+6I+DnwX4CfAY+S39Xwmyzy4y7MdYwH/f2WShBolnWLdt6spOXA9cD7I2LnoNtTJUmvBx6PiNsH3ZbDrA6cDnw+In4D2M3RPxyyoGJc/HzgFOAEYJmktw62VQN30N9vqQTBNuDE0vJa8u7koiOpQR4CfxsRNxSrfyHpucX25wKPD6p9FXgp8LuSfko+5PcqSV9kcR8z5P+mt0XErcXyl8mDYbEf92uAhyJiNCImgRuAf8niP26Y+xgP+vstlSC4DVgv6RRJQ+SFlc0DbtMhJ0nkY8b3RsR/LW3aDPxh8fwPga8e7rZVJSI+EhFrI2Id+d/r/46It7KIjxkgIh4DHpH0gmLVq4F7WOTHTT4kdJakpcW/91eT18IW+3HD3Me4GbhAUlPSKcB64J/3650jIokf4DzgfuAB4KODbk9Fx/gy8i7hHcAPi5/zgFXkswx+UjweP+i2VnT8rwS+Vjxf9McMvATYUvx9fwU4LpHj/nPgx8BdwH8HmovtuIFryWsgk+S/8b9rvmMEPlp8t90HnLu/n+dLTJiZJS6VoSEzM5uDg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DsAEh6v6Slg26H2aHg6aNmB6A4k3lDRDwx6LaYHaz6oBtgdqQrLub2P8hP3c+Avye/zs0/SXoiIs6R9FryE52a5Cf2vDMidhWB8XfAOcXbvTkith7uYzCbj4eGzBa2EdgeEadFfg38y8iv5XJOEQKrgUuB10TE6eRn+36g9PqdEXEm8LnitWZHFAeB2cLuBF4j6VOSXh4RT/dsP4v8hkf/V9IPya8Dc3Jp+7Wlx7Mrb63ZfvLQkNkCIuJ+Sb9Jft2m/yTpmz27CPhWRFw411vM8dzsiOAegdkCJJ0A7ImIL5LfFOV04BlgRbHLLcBLJf1qsf9SSc8vvcWbSo/fPzytNuufewRmC3sR8GlJHfKrQf478iGer0t6tKgTvAO4VlKzeM2l5Fe7BWhKupX8F6+5eg1mA+Ppo2YV8jRTOxp4aMjMLHHuEZiZJc49AjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxP1/pUuZxCa8JY0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title('loss')\n",
    "plt.plot(np.arange(len(v_losses)), v_losses)\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('losss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
